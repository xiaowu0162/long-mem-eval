<!DOCTYPE html>
<html class="fontawesome-i2svg-active fontawesome-i2svg-complete">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <meta name="viewport" content="width=device-width, initial-scale=1">
    

    <style>
        .content {
            font-size: 22px; /* Adjust the font size as desired */
        }
        img {
            padding: 15px 0; /* Adjust the value (20px) as needed for vertical spacing */
        }
    </style>

    <style type="text/css">svg:not(:root).svg-inline--fa {
        overflow: visible
    }

    .svg-inline--fa {
        display: inline-block;
        font-size: inherit;
        height: 1em;
        overflow: visible;
        vertical-align: -.125em
    }

    .svg-inline--fa.fa-lg {
        vertical-align: -.225em
    }

    .svg-inline--fa.fa-w-1 {
        width: .0625em
    }

    .svg-inline--fa.fa-w-2 {
        width: .125em
    }

    .svg-inline--fa.fa-w-3 {
        width: .1875em
    }

    .svg-inline--fa.fa-w-4 {
        width: .25em
    }

    .svg-inline--fa.fa-w-5 {
        width: .3125em
    }

    .svg-inline--fa.fa-w-6 {
        width: .375em
    }

    .svg-inline--fa.fa-w-7 {
        width: .4375em
    }

    .svg-inline--fa.fa-w-8 {
        width: .5em
    }

    .svg-inline--fa.fa-w-9 {
        width: .5625em
    }

    .svg-inline--fa.fa-w-10 {
        width: .625em
    }

    .svg-inline--fa.fa-w-11 {
        width: .6875em
    }

    .svg-inline--fa.fa-w-12 {
        width: .75em
    }

    .svg-inline--fa.fa-w-13 {
        width: .8125em
    }

    .svg-inline--fa.fa-w-14 {
        width: .875em
    }

    .svg-inline--fa.fa-w-15 {
        width: .9375em
    }

    .svg-inline--fa.fa-w-16 {
        width: 1em
    }

    .svg-inline--fa.fa-w-17 {
        width: 1.0625em
    }

    .svg-inline--fa.fa-w-18 {
        width: 1.125em
    }

    .svg-inline--fa.fa-w-19 {
        width: 1.1875em
    }

    .svg-inline--fa.fa-w-20 {
        width: 1.25em
    }

    .svg-inline--fa.fa-pull-left {
        margin-right: .3em;
        width: auto
    }

    .svg-inline--fa.fa-pull-right {
        margin-left: .3em;
        width: auto
    }

    .svg-inline--fa.fa-border {
        height: 1.5em
    }

    .svg-inline--fa.fa-li {
        width: 2em
    }

    .svg-inline--fa.fa-fw {
        width: 1.25em
    }

    .fa-layers svg.svg-inline--fa {
        bottom: 0;
        left: 0;
        margin: auto;
        position: absolute;
        right: 0;
        top: 0
    }

    .fa-layers {
        display: inline-block;
        height: 1em;
        position: relative;
        text-align: center;
        vertical-align: -.125em;
        width: 1em
    }

    .fa-layers svg.svg-inline--fa {
        -webkit-transform-origin: center center;
        transform-origin: center center
    }

    .fa-layers-counter, .fa-layers-text {
        display: inline-block;
        position: absolute;
        text-align: center
    }

    .fa-layers-text {
        left: 50%;
        top: 50%;
        -webkit-transform: translate(-50%, -50%);
        transform: translate(-50%, -50%);
        -webkit-transform-origin: center center;
        transform-origin: center center
    }

    .fa-layers-counter {
        background-color: #ff253a;
        border-radius: 1em;
        -webkit-box-sizing: border-box;
        box-sizing: border-box;
        color: #fff;
        height: 1.5em;
        line-height: 1;
        max-width: 5em;
        min-width: 1.5em;
        overflow: hidden;
        padding: .25em;
        right: 0;
        text-overflow: ellipsis;
        top: 0;
        -webkit-transform: scale(.25);
        transform: scale(.25);
        -webkit-transform-origin: top right;
        transform-origin: top right
    }

    .fa-layers-bottom-right {
        bottom: 0;
        right: 0;
        top: auto;
        -webkit-transform: scale(.25);
        transform: scale(.25);
        -webkit-transform-origin: bottom right;
        transform-origin: bottom right
    }

    .fa-layers-bottom-left {
        bottom: 0;
        left: 0;
        right: auto;
        top: auto;
        -webkit-transform: scale(.25);
        transform: scale(.25);
        -webkit-transform-origin: bottom left;
        transform-origin: bottom left
    }

    .fa-layers-top-right {
        right: 0;
        top: 0;
        -webkit-transform: scale(.25);
        transform: scale(.25);
        -webkit-transform-origin: top right;
        transform-origin: top right
    }

    .fa-layers-top-left {
        left: 0;
        right: auto;
        top: 0;
        -webkit-transform: scale(.25);
        transform: scale(.25);
        -webkit-transform-origin: top left;
        transform-origin: top left
    }

    .fa-lg {
        font-size: 1.3333333333em;
        line-height: .75em;
        vertical-align: -.0667em
    }

    .fa-xs {
        font-size: .75em
    }

    .fa-sm {
        font-size: .875em
    }

    .fa-1x {
        font-size: 1em
    }

    .fa-2x {
        font-size: 2em
    }

    .fa-3x {
        font-size: 3em
    }

    .fa-4x {
        font-size: 4em
    }

    .fa-5x {
        font-size: 5em
    }

    .fa-6x {
        font-size: 6em
    }

    .fa-7x {
        font-size: 7em
    }

    .fa-8x {
        font-size: 8em
    }

    .fa-9x {
        font-size: 9em
    }

    .fa-10x {
        font-size: 10em
    }

    .fa-fw {
        text-align: center;
        width: 1.25em
    }

    .fa-ul {
        list-style-type: none;
        margin-left: 2.5em;
        padding-left: 0
    }

    .fa-ul > li {
        position: relative
    }

    .fa-li {
        left: -2em;
        position: absolute;
        text-align: center;
        width: 2em;
        line-height: inherit
    }

    .fa-border {
        border: solid .08em #eee;
        border-radius: .1em;
        padding: .2em .25em .15em
    }

    .fa-pull-left {
        float: left
    }

    .fa-pull-right {
        float: right
    }

    .fa.fa-pull-left, .fab.fa-pull-left, .fal.fa-pull-left, .far.fa-pull-left, .fas.fa-pull-left {
        margin-right: .3em
    }

    .fa.fa-pull-right, .fab.fa-pull-right, .fal.fa-pull-right, .far.fa-pull-right, .fas.fa-pull-right {
        margin-left: .3em
    }

    .fa-spin {
        -webkit-animation: fa-spin 2s infinite linear;
        animation: fa-spin 2s infinite linear
    }

    .fa-pulse {
        -webkit-animation: fa-spin 1s infinite steps(8);
        animation: fa-spin 1s infinite steps(8)
    }

    @-webkit-keyframes fa-spin {
        0% {
            -webkit-transform: rotate(0);
            transform: rotate(0)
        }
        100% {
            -webkit-transform: rotate(360deg);
            transform: rotate(360deg)
        }
    }

    @keyframes fa-spin {
        0% {
            -webkit-transform: rotate(0);
            transform: rotate(0)
        }
        100% {
            -webkit-transform: rotate(360deg);
            transform: rotate(360deg)
        }
    }

    .fa-rotate-90 {
        -webkit-transform: rotate(90deg);
        transform: rotate(90deg)
    }

    .fa-rotate-180 {
        -webkit-transform: rotate(180deg);
        transform: rotate(180deg)
    }

    .fa-rotate-270 {
        -webkit-transform: rotate(270deg);
        transform: rotate(270deg)
    }

    .fa-flip-horizontal {
        -webkit-transform: scale(-1, 1);
        transform: scale(-1, 1)
    }

    .fa-flip-vertical {
        -webkit-transform: scale(1, -1);
        transform: scale(1, -1)
    }

    .fa-flip-both, .fa-flip-horizontal.fa-flip-vertical {
        -webkit-transform: scale(-1, -1);
        transform: scale(-1, -1)
    }

    :root .fa-flip-both, :root .fa-flip-horizontal, :root .fa-flip-vertical, :root .fa-rotate-180, :root .fa-rotate-270, :root .fa-rotate-90 {
        -webkit-filter: none;
        filter: none
    }

    .fa-stack {
        display: inline-block;
        height: 2em;
        position: relative;
        width: 2.5em
    }

    .fa-stack-1x, .fa-stack-2x {
        bottom: 0;
        left: 0;
        margin: auto;
        position: absolute;
        right: 0;
        top: 0
    }

    .svg-inline--fa.fa-stack-1x {
        height: 1em;
        width: 1.25em
    }

    .svg-inline--fa.fa-stack-2x {
        height: 2em;
        width: 2.5em
    }

    .fa-inverse {
        color: #fff
    }

    .sr-only {
        border: 0;
        clip: rect(0, 0, 0, 0);
        height: 1px;
        margin: -1px;
        overflow: hidden;
        padding: 0;
        position: absolute;
        width: 1px
    }

    .sr-only-focusable:active, .sr-only-focusable:focus {
        clip: auto;
        height: auto;
        margin: 0;
        overflow: visible;
        position: static;
        width: auto
    }

    .svg-inline--fa .fa-primary {
        fill: var(--fa-primary-color, currentColor);
        opacity: 1;
        opacity: var(--fa-primary-opacity, 1)
    }

    .svg-inline--fa .fa-secondary {
        fill: var(--fa-secondary-color, currentColor);
        opacity: .4;
        opacity: var(--fa-secondary-opacity, .4)
    }

    .svg-inline--fa.fa-swap-opacity .fa-primary {
        opacity: .4;
        opacity: var(--fa-secondary-opacity, .4)
    }

    .svg-inline--fa.fa-swap-opacity .fa-secondary {
        opacity: 1;
        opacity: var(--fa-primary-opacity, 1)
    }

    .svg-inline--fa mask .fa-primary, .svg-inline--fa mask .fa-secondary {
        fill: #000
    }

    .fad.fa-inverse {
        color: #fff
    }</style>
    <link rel="stylesheet" href="src/codemirror.min.css">
    <script src="src/runmode-standalone.min.js"></script>
    <script src="src/python.min.js"></script>

    <title>LongMemEval</title>


    <!-- Google tag (gtag.js)
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-S3G8BGY5W5"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-S3G8BGY5W5');
    </script>
    -->

    <link href="src/css" rel="stylesheet">

    <link rel="stylesheet" href="src/bulma.min.css">
    <link rel="stylesheet" href="src/bulma-carousel.min.css">
    <link rel="stylesheet" href="src/bulma-slider.min.css">
    <link rel="stylesheet" href="src/fontawesome.all.min.css">
    <link rel="stylesheet" href="src/academicons.min.css">
    <link rel="stylesheet" href="src/index.css">
    <link rel="icon" href="src/uclanlp.png">

    <script src="src/jquery.min.js"></script>
    <script defer="" src="src/fontawesome.all.min.js"></script>
    <script src="src/bulma-carousel.min.js"></script>
    <script src="src/bulma-slider.min.js"></script>
    <script src="src/index.js"></script>
</head>
<body>


<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title">
                        <!-- <span class="contextual" style="vertical-align: middle">Repoformer</span> -->
                        </h1>
                    <h2 class="subtitle is-3 publication-subtitle" >
                        <b><span class="dnerf">LongMemEval</span>: Benchmarking Chat Assistants on Long-Term Interactive Memory</b></h2>
                    <!-- <h3><strong>Accepted at ICML 2024 (Main Track)</strong>🎉</h3> -->
                    <div class="is-size-5 publication-authors">
                        <span class="author-block">
                            <a href="https://xiaowu0162.github.io/">Di Wu<sup>1</sup></a>,&nbsp;
                        </span>
                        <span class="author-block">
                            <a href="https://hongweiw.net/">Hongwei Wang<sup>2</sup></a>,&nbsp;
                        </span>
                        <span class="author-block">
                            <a href="https://wyu97.github.io/">Wenhao Yu<sup>2</sup></a>,&nbsp;
                        </span>
                        <span class="author-block">
                            <a href="https://zhang-yu-wei.github.io/">Yuwei Zhang<sup>3</sup></a>,
                        </span>
                        
                        </span><span class="author-block">
                            <a href="https://web.cs.ucla.edu/~kwchang//">Kai-Wei Chang<sup>1</sup></a>,
                        </span>
                        <span class="author-block">
                            <a href="https://sites.google.com/view/dongyu888/">Dong Yu<sup>2</sup></a>,&nbsp;
                        </span>
                    
                    </div>

                    <div class="is-size-5 publication-authors">
                        <span class="author-block"><sup>1</sup>UCLA</span>, <span
                            class="author-block"><sup>2</sup>Tencent AI Lab Seattle</span>, <span
                            class="author-block"><sup>3</sup>UC San Diego</span>
                    </div>

                    <div class="column has-text-centered">
                        <div class="publication-links">
                            
                            <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2406.13692" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
                            
                            
                            <!-- Code Link. -->
                            <span class="link-block">
                <a href="https://github.com/xiaowu0162/LongMemEval"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <svg class="svg-inline--fa fa-github fa-w-16" aria-hidden="true" focusable="false"
                           data-prefix="fab" data-icon="github" role="img" xmlns="http://www.w3.org/2000/svg"
                           viewBox="0 0 496 512" data-fa-i2svg=""><path fill="currentColor"
                                                                        d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg>
                      <!-- <i class="fab fa-github"></i> Font Awesome fontawesome.com -->
                  </span>
                  <span>Code</span>
                  </a>
              </span>
                            <!-- Model Link. -->


                            <!-- Twitter Link -->
              <span class="link-block">
                <a href="https://x.com/DiWu0162/status/1806420008400257323" target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <p style="font-size:18px">🌐</p>
                  </span>
                  <span>Twitter</span>
                </a>
              </span>


                        </div>

                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="section hero is-small">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
          <div class="content has-text-justified">
              <h2 class="subtitle is-size-3-tablet has-text-weight-bold has-text-centered has-background-info-light mr-0 pt-3 pb-3">
                Highlights
              </h2>
                <center>
                    <p>
                    We introduce <b><span class="dnerf">LongMemEval</span></b>, a comprehensive, challenging, and scalable benchmark for testing the long-term memory of chat assistants.
                    </p>
                </center>
            <br>
            <img src="figures/1_examples.png" class="center">
                
        </div>
      </div>
    </div>
</section>


<section class="section">
    <div class="container is-max-desktop">
          <h2 class="subtitle is-size-3-tablet has-text-weight-bold has-text-centered has-background-info-light mr-0 pt-3 pb-3">
        Benchmark Construction
           </h2>
          <div class="content has-text-justified">
            <p>
                We meticulously create 500 questions of seven types (see examples above) to test five long-term memory abilities: 
                <ul>
                    <li><b>Information Extraction</b>: Ability to recall specific information from extensive interactive histories, including the details mentioned by either the user or the assistant.</li>
                    <li><b>Multi-Session Reasoning</b>: Ability to synthesize the information across multiple history sessions to answer complex questions that involve aggregation and comparison.</li>
                    <li><b>Knowledge Updates</b>: Ability to recognize the changes in the user’s personal information and update the knowledge of the user dynamically over time.</li>
                    <li><b>Temporal Reasoning</b>: Awareness of the temporal aspects of user information, including both explicit time mentions and timestamp metadata in the interactions.</li>
                    <li><b>Abstention</b>: Ability to refrain from answering questions that involve unknown information, i.e., information not mentioned in the interaction history.</li>
                  </ul>
            </p>
            
            <img src="figures/2_data_pipeline.png" class="center" class="center", style="width: 100%; display: block; margin: auto;">
            <p>The following figure showcases the question distribution, the number of sessions required to find the answer, and the location of the evidence statements inside sessions. </p>
            <img src="figures/3_basic_stats.png" class="center" class="center", style="width: 100%; display: block; margin: auto;">
            <p>
                Inspired by the "needle-in-a-haystack" test, we design an attribute-controlled pipeline to compile a coherent, extensible, and timestamped chat history for each question. Two standard test sets are created: 
                <ul>
                    <li><b><span class="dnerf">LongMemEval<sub>S</sub></span></b>: each question's chat history has roughly 115k tokens (30-40 sessions)</li>
                    <li><b><span class="dnerf">LongMemEval<sub>M</sub></span></b>: each question's chat history has roughly 500 sessions (~1.5M tokens)</li>
                  </ul>
            </p>
          </div>
    </div>
</section>


<section class="section">
    <div class="container is-max-desktop">
          <h2 class="subtitle is-size-3-tablet has-text-weight-bold has-text-centered has-background-info-light mr-0 pt-3 pb-3">
            LongMemEval is Challenging
           </h2>
          <div class="content has-text-justified">
            <p>
                Surprisingly, we find long-context LLMs show a <b>30%∼60% performance drop</b> on <span class="dnerf">LongMemEval<sub>S</sub></span>, and manual evaluations reveal that state-of-the-art commercial systems (such as GPT-4o) only achieve <b>30%∼70% accuracy</b> in a setting much simpler than <span class="dnerf">LongMemEval<sub>S</sub></span>. Even the most capable long-context LLMs currently would require an effective memory mechanism to manage an ever-growing interaction history.
            </p>
            <img src="figures/4_longmemeval_challenging.png" class="center" class="center", style="width: 100%; display: block; margin: auto;">
          </div>
    </div>
</section>


<section class="section">
    <div class="container is-max-desktop">
          <h2 class="subtitle is-size-3-tablet has-text-weight-bold has-text-centered has-background-info-light mr-0 pt-3 pb-3">
        A Unified View of Memory Systems
           </h2>
          <div class="content has-text-justified">
            <p>
                Finally, we formulate a three-stage long-term memory model for chat assistants. Despite its simplicity, this model provides a unified view of existing long-term memory assistant works and enables us to investigate four crucial control points for each stage’s design.
            </p>
            <img src="figures/5_memory_unified_view.png" class="center" class="center", style="width: 100%; display: block; margin: auto;">
            <p>
                <b>[Finding 1]</b> Instead of sessions, <b>round</b> is the best granularity for storing and utilizing the interactive history. While further compression into individual user facts harms overall performance due to information loss, it improves the multi-session reasoning performance.
            </p>
            <img src="figures/6_value_results.png" class="center" class="center", style="width: 100%; display: block; margin: auto;">
            <p>
                <b>[Finding 2]</b> While using a flat index with the memory values themselves as the keys is a strong baseline, <b>expanding the keys with extracted user facts</b> greatly facilitates both memory recall (4% higher recall@k) and downstream question answering (5% higher accuracy).
            </p>
            <img src="figures/7_key_results.png" class="center" class="center", style="width: 100%; display: block; margin: auto;">
            <p>
                <b>[Finding 3]</b> Simplistic memory designs perform poorly on temporal reasoning questions. We propose a simple <b>time-aware indexing and query expansion</b> strategy to narrow down the search range, which improves the memory recall for the temporal reasoning by 7%∼11%.
            </p>
            <img src="figures/8_query_results.png" class="center" class="center", style="width: 100%; display: block; margin: auto;">
            <p>
                <b>[Finding 4]</b> Even with perfect memory recall, accurately reading the retrieved items is still non- trivial. Applying <b>Chain-of-Note</b> and <b>structured JSON prompt format</b> improves the reading accuracy by as much as 10 absolute points across three LLMs.
            </p>
            <img src="figures/9_reading_results.png" class="center" class="center", style="width: 100%; display: block; margin: auto;">
          </div>
    </div>
</section>

<section class="section" id="BibTeX">
    <div class="container is-max-desktop" content> 
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{wu2024longmemeval,
	  title={LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory}, 
	  author={Di Wu and Hongwei Wang and Wenhao Yu and Yuwei Zhang and Kai-Wei Chang and Dong Yu},
	  year={2024},
	  eprint={2410.10813},
	  archivePrefix={arXiv},
	  primaryClass={cs.CL},
	  url={https://arxiv.org/abs/2410.10813}, 
	  }</code></pre>
    </div>
</section>
 

  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p style="color:gray;font-size:9.9px;">
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>
 

</body>
</html>
